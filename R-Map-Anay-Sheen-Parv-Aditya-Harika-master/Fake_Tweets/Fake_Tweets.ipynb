{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sentiment words 323 578\n"
     ]
    }
   ],
   "source": [
    "pos = []\n",
    "neg = []\n",
    "\n",
    "new_dir = \"/home/local/ASUAD/arohill1/Academics/Fake_Tweets\"\n",
    "def get_sentiment_words():\n",
    "    with open(new_dir + '/' + 'pos.txt') as read_file:\n",
    "        for row in read_file:\n",
    "            pos.append(str(row))\n",
    "            \n",
    "    with open(new_dir + '/' + 'neg.txt') as read_file:\n",
    "        for row in read_file:\n",
    "            neg.append(str(row))\n",
    "\n",
    "get_sentiment_words()\n",
    "\n",
    "print(\"Length of sentiment words\", len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-95670deab6d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msame_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tue Nov 26 16:16:33 +0000 2019'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-95670deab6d9>\u001b[0m in \u001b[0;36msame_time\u001b[0;34m(time)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msame_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m    clean_timestamp = datetime.strptime(time,\n\u001b[0m\u001b[1;32m     17\u001b[0m                       '%a %b %d %H:%M:%S +0000 %Y')\n\u001b[1;32m     18\u001b[0m    final_timestamp =  datetime.strftime(clean_timestamp, \n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    " def time_change(time):\n",
    "    \n",
    "    clean_timestamp = datetime.strptime(time,\n",
    "                       '%a %b %d %H:%M:%S +0000 %Y')\n",
    "    offset_hours = random.randint(1, 10)\n",
    "\n",
    "     #account for offset from UTC using timedelta                                \n",
    "    local_timestamp = clean_timestamp + timedelta(hours=offset_hours)\n",
    "\n",
    "     #convert to am/pm format for easy reading\n",
    "    final_timestamp =  datetime.strftime(local_timestamp, \n",
    "                        '%Y-%m-%d %I:%M:%S %p')  \n",
    "    return final_timestamp\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "def same_time(time):\n",
    "    clean_timestamp = datetime.strptime(time,\n",
    "                       '%a %b %d %H:%M:%S +0000 %Y')\n",
    "    final_timestamp =  datetime.strftime(clean_timestamp, \n",
    "                        '%Y-%m-%d %I:%M:%S %p')  \n",
    "    return final_timestamp\n",
    "\n",
    "print(same_time('Tue Nov 26 16:16:33 +0000 2019'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Tweets in file: @BernieSanders1202779467082543104.json 1006\n",
      "Length of Tweets in file: @BarackObama1199754566130114567.json 1005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#getting json data\n",
    "\n",
    "import os, json, csv\n",
    "import random, string\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "orig_name = [\"JimCarrey\", \"JustinTrudeau\", \"BernieSanders\", \"narendramodi\",\n",
    "                 \"BorisJohnson\", \"HillaryClinton\", \"BarackObama\", \"katyperry\",  \"shakira\", \"RahulGandhi\",\n",
    "                 \"TheEllenShow\", \"realDonaldTrump\", \"ArianaGrande\", \"taylorswift13\", \"Cristiano\",\n",
    "                 \"justinbieber\", \"jonasbrothers\", \"KylieJenner\", \"jeremycorbyn\", \"elonmusk\"]\n",
    "\n",
    "\n",
    "directory = \"/home/local/ASUAD/arohill1/Academics/Fake_Tweets/new_pol\"\n",
    "new_directory = \"/home/local/ASUAD/arohill1/Academics/Fake_Tweets/politics_csv/\"\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".json\"): \n",
    "        with open(directory + '/' + filename) as read_file:\n",
    "            \n",
    "            data = json.load(read_file)\n",
    "            print('Length of Tweets in file: ' + filename, len(data)) \n",
    "            \n",
    "            file_name_csv = filename.rsplit('.')\n",
    "            file_name_csv = file_name_csv[0]\n",
    "            with open(new_directory + file_name_csv +'.csv', mode='w') as csv_file:\n",
    "                \n",
    "                csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "                csv_writer.writerow(['created_at', 'tweet_id', 'full_text', 'user_id', 'user_name', 'user_screen_name', 'is_retweet', 'retweeted_status_id', 'retweeted_status_text', 'is_quoted', 'is_politics'])\n",
    "                \n",
    "                for row in range(0, len(data)):\n",
    "                    if data[row]['user']['screen_name'] in orig_name:\n",
    "                        is_retweet = 'False'\n",
    "                        retweet_id = \"\"\n",
    "                        retweet_text = \"\"\n",
    "                    elif 'retweeted_status' in data[row]:\n",
    "                        is_retweet = 'True'\n",
    "                        retweet_id = data[row]['retweeted_status']['id_str']\n",
    "                        retweet_text = data[row]['retweeted_status']['full_text']\n",
    "                        \n",
    "                        fif_num = 15/100 * len(data)\n",
    "                        \n",
    "                        if row < fif_num:\n",
    "                        \n",
    "                            if len(data) < 600:\n",
    "                                num_level = random.randint(0, int( len(data)/5) )\n",
    "                            else:\n",
    "                                num_level = random.randint(0, int( len(data)/10) )\n",
    "\n",
    "\n",
    "                            sentiment_num = random.randint(0, num_level)\n",
    "\n",
    "                            #print(\"The number of retweets created is: \" , num_level)\n",
    "\n",
    "                            for i in range(0, num_level):\n",
    "                                new_tweet_id = str(random.randint(100000, 999999)) + str(i)\n",
    "                                new_u_id = str(random.randint(1000, 9999)) + str(i)\n",
    "                                new_u_name = ''.join([random.choice(string.ascii_letters + string.digits) for n in range(8)])\n",
    "                                new_u_screen_name =''.join([random.choice(string.ascii_letters + string.digits) for n in range(15)])\n",
    "                                new_time = time_change(data[row]['created_at'])\n",
    "                                if i < sentiment_num:\n",
    "                                    new_text = str(random.choice(pos)  + random.choice(pos) + random.choice(pos) + \".\")\n",
    "                                else:\n",
    "                                    new_text = str(random.choice(neg) + random.choice(neg)  + random.choice(neg) + \".\")\n",
    "                                #new_text = new_text.rsplit('\\n')\n",
    "                                #new_text = new_text[0] + ' ' + new_text[1] + ' ' + new_text[2]\n",
    "                                csv_writer.writerow([new_time,new_tweet_id, new_text, new_u_id, new_u_name, new_u_screen_name, 'True', data[row]['id_str'], data[row]['full_text'], 'True', 'False'])\n",
    "\n",
    "\n",
    "\n",
    "                    csv_writer.writerow([same_time(data[row]['created_at']), data[row]['id_str'], data[row]['full_text'], data[row]['user']['id_str'], data[row]['user']['name'], data[row]['user']['screen_name'], is_retweet, retweet_id, retweet_text, data[row]['is_quote_status'], 'True'])\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
